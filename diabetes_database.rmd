---
title: "Aprendizagem Estatística em Altas Dimensões [MAE0501/MAE5904/IBI5904]"
author: |
  | Ícaro Maia Santos de Castro\thanks{Número USP: 11866921}
  | Rayssa de Carvalho Roberto\thanks{Número USP: 10940828}
  | Rodrigo Aoyama Nakahara\thanks{Número USP: 3510922} 
  | Rodrigo Araujo\thanks{Número USP: 9299208}
  | Vitor Hugo Vieira de Lima\thanks{Número USP: 10263886}
date: "`r stringr::str_to_sentence(format(Sys.time(), '%B de %Y'))`"
lang: pt-BR
header-includes:
  # - \usepackage[brazilian]{babel}
  - \usepackage{float}
  - \usepackage{amsmath}
  - \usepackage{amsthm}
  - \floatplacement{figure}{H}
  - \usepackage{indentfirst}
  - \setlength{\parindent}{4em}
  - \setlength{\parskip}{1em}
  - \usepackage{booktabs}
  - \usepackage{dcolumn}
  - \usepackage{bm}
  - \usepackage{titling}
  - \thanksmarkseries{arabic} % \thanks footnotes com numeros
  - \usepackage[bottom]{footmisc} % corrige posição footnotes
  - \usepackage{pdfpages}
  - \usepackage{tocloft}
  - \renewcommand{\cftsecleader}{\cftdotfill{\cftdotsep}}
  - \usepackage{amssymb}
  - \renewcommand\qedsymbol{$\blacksquare$}
  - \usepackage{cleveref}
output: 
  pdf_document: 
    fig_caption: yes
    # number_sections: yes
    toc: true
    toc_depth: 2
#keep_tex: true
editor_options: 
  chunk_output_type: console
# bibliography: ref.bib
---
  
\pagebreak

\newcommand\invisiblesection[1]{%
  \refstepcounter{section}%
  \addcontentsline{toc}{section}{#1}%
  \sectionmark{#1}}
  
<!-- \newcommand\invisiblesection[1]{% -->
<!--   \refstepcounter{section}% -->
<!--   \addcontentsline{toc}{section}{\protect\numberline{\thesection}#1}% -->
<!--   \sectionmark{#1}} -->

<!-- \newcommand\invisiblessection[1]{% -->
<!--   \refstepcounter{subsection}% -->
<!--   \addcontentsline{toc}{subsection}{\protect\numberline{\thesection}#1}% -->
<!--   \sectionmark{#1}} -->

```{r setup, include=FALSE}
# options(tinytex.verbose = TRUE)

# template com paramentros padrao para as figuras
knitr::opts_template$set(figuras = list(echo = FALSE, 
                                        results='hide', 
                                        fig.show = "hold",
                                        fig.align = 'center',
                                        fig.ncol = 1,
                                        # fig.width = 4,
                                        # fig.height = 4,
                                        out.width = "\\textwidth",
                                        out.height = "0.9\\textheight"
))
knitr::opts_template$set(figuras2 = list(echo = FALSE, 
                                         results='hide', 
                                         fig.show = "hold",
                                         fig.align = 'center',
                                         fig.ncol = 2,
                                         fig.width = 4,
                                         out.width = "0.48\\textwidth", 
                                         out.height = "0.30\\textheight"))

knitr::opts_template$set(
  series = list(echo = FALSE, 
                results='hide', 
                fig.show = "hold",
                warning=FALSE,
                fig.align = 'center',
                fig.ncol = 1,
                fig.heigth=3, 
                fig.width=16
                # out.width = "\\textheight"
                ))

# uso: <<r, opts.label='figuras'>>=
# uso: ```{r, opts.label='figuras'}


```

```{r libs, include=FALSE}
library(tidyverse)
library(knitr)
library(stargazer)
library(tidyverse)
library(kableExtra)
library(ggplot2)
library(readxl)
library(MASS)
library(psych)
library(Hmisc)
library(GPArotation)
library(corrplot)


library(dplyr)
library(visdat)
library(VIM)
library(ggplot2)
library(naniar)

library(MLmetrics)
library(ROCR)
library(pROC)

library(modelr)
library(dplyr)


library(vegan)
```

```{r func_aux, include=FALSE}
# Funções auxliares ----

kable <- function(...) {
  args <- list(
    ...,
    {if(!interactive() & knitr::is_latex_output()) format = 'latex'},
    digits = 2,
    booktabs = TRUE,
    format.args = list(
      # scientific=T,
      # nsmall = 2,
      decimal.mark = ",", 
      big.mark = "."
      )
    )
  
  args <- args[!duplicated(names(args))]
  
  do.call(knitr::kable, args) %>% kable_styling(latex_options = "HOLD_position")
}



```




# Importando os dados / Limpando / Inspecionando 



```{r}

diabetes <- read_csv("C:\\Users\\Rodrigo Araujo\\Documents\\IME-USP\\Aprendizagem Estatística em Altas Dimensões\\diabetes-database-mae0501\\diabetes.csv")

#diabetes <- read.csv("diabetes.csv")
head(diabetes) %>% kable(caption="Dados.")

dim(diabetes)

```


## Renomear coluna e ajustar níveis de categórica

```{r}

diabetes[, 2:6][diabetes[, 2:6] == 0] <- NA

colnames(diabetes)[9] <- "diabetes"

diabetes$diabetes <- as.factor(diabetes$diabetes)

levels(diabetes$diabetes) <- c("No","Yes")

```


## Visualização dos Dados {.tabset}

### Estrutura dos Dados

```{r}

str(diabetes)

```





# Analise dos Missings

## Descritiva inicial

```{r, warning=FALSE}

summary(diabetes)

```



```{r}
vis_dat(diabetes)

```

```{r}
vis_miss(diabetes)

```

```{r}
aggr(diabetes) # Missings têm padrões?

```

```{r}
ggplot(diabetes, aes(x = Insulin, y = SkinThickness)) + # Padrão de missing entre 2 vars com mais missings?
  geom_miss_point()

```

```{r}
ggplot(diabetes, aes(x = Insulin, y = SkinThickness)) + # Padrão de missing entre 2 vars com mais missings por categoria da resposta
  geom_miss_point() + facet_wrap(~ diabetes)

marginplot(diabetes[c(4,5)])

```


## Possibilidades de imputação

```{r}
library(mice)

imputacao1 <- mice(data = diabetes , m = 5, maxit = 50, meth = 'pmm', seed = 25)
summary(imputacao1)

``` 


```{r}
imputado1 <- complete(imputacao1, 1)
imputado2 <- complete(imputacao1, 2)
imputado3 <- complete(imputacao1, 3)
imputado4 <- complete(imputacao1, 4)
imputado5 <- complete(imputacao1, 5)

library(lattice)
densityplot(imputacao1)

``` 

```{r}
  
diabetes$Glucose <- apply(cbind(imputado1$Glucose, imputado2$Glucose, imputado3$Glucose, imputado4$Glucose, imputado5$Glucose), 1, mean)  

diabetes$BloodPressure <- apply(cbind(imputado1$BloodPressure, imputado2$BloodPressure, imputado3$BloodPressure, imputado4$BloodPressure, imputado5$BloodPressure), 1, mean)  

diabetes$SkinThickness <- apply(cbind(imputado1$SkinThickness, imputado2$SkinThickness, imputado3$SkinThickness, imputado4$SkinThickness, imputado5$SkinThickness), 1, mean)  

diabetes$Insulin <- apply(cbind(imputado1$Insulin, imputado2$Insulin, imputado3$Insulin, imputado4$Insulin, imputado5$Insulin), 1, mean)  

diabetes$BMI <- apply(cbind(imputado1$BMI, imputado2$BMI, imputado3$BMI, imputado4$BMI, imputado5$BMI), 1, mean)  

```



# train / test

```{r, warning=FALSE}

# para reprodução
set.seed(23) 
nrows <- nrow(diabetes)
index <- sample(1:nrows, 0.7 * nrows)	# shuffle and divide
# train <- diab                         # 768 test data (100%)
train <- diabetes[index,]			        # 537 test data (70%)
test <- diabetes[-index,]  		            # 231 test data (30%)


```


## Proporção de diabetes (Benign / Malignant) {.tabset}

### train

```{r}

prop.table(table(train$diabetes))

```

### test

```{r}

prop.table(table(test$diabetes))

```


# Análise Descritiva

## Distribuição da variável Diabetes 


```{r, warning=FALSE}

ggplot(train, aes(diabetes, fill = diabetes)) + 
  geom_bar() +
  theme_bw() +
  labs(title = "Classificação Diabetes", x = "Diabetes") +
  theme(plot.title = element_text(hjust = 0.5))

```


## Correlação entre cada variável

```{r, warning=FALSE}

library(PerformanceAnalytics)

chart.Correlation(train[,-9], histogram=TRUE, col="grey10", pch=1, main="Correlação entre ás variáveis explicativas")

```




```{r, warning=FALSE}
library(ggcorrplot)

corr<-round(cor(train[,-9]),1)
ggcorrplot(corr, hc.order = TRUE, 
           type = "lower", 
           lab = TRUE, 
           lab_size = 3, 
           method="circle", 
           colors = c("red", "white", "blue"), 
           title="Correlogram of Diabetes data", 
           ggtheme=theme_bw)

```




# Modelagem

## SVM

```{r, warning=FALSE}
library(caret)
library(e1071)

set.seed(123)

linear.tune <- e1071::tune.svm(diabetes ~.,
                                data   = train,
                                kernel = 'linear',
                                cost   = c(0.001, 0.01, 0.1, 1, 5, 10))
summary(linear.tune)

```

Matriz de Confusão

```{r, warning=FALSE}

svm.real <- test$diabetes

best.linear <- linear.tune$best.model
tune.test <- predict(best.linear, test[,-9])

caret::confusionMatrix(data = tune.test,
                       reference = svm.real,
                       positive  = 'Yes')

```

Curva ROC

```{r, warning=FALSE}

svm.predobj <- ROCR::prediction(predictions = as.numeric(x = tune.test ),
                            labels      = as.numeric(x = svm.real))
svm.perform <- ROCR::performance(prediction.obj = svm.predobj,
                                 measure        = 'tpr',
                                 x.measure      = 'fpr')
plot(x = svm.perform, main = 'ROC curve')
MLmetrics::F1_Score(y_pred   = tune.test ,
                    y_true   = svm.real,
                    positive = "Yes"); pROC::auc(response = as.numeric(x = svm.real),
                                                 predictor = as.numeric(x = tune.test))

```


## RandomForest

```{r, warning=FALSE}
library(randomForest)

learn_rf <- randomForest(diabetes~., data=train, ntree=500, proximity=T, importance=T)

pre_rf   <- predict(learn_rf, test[,-9])

cm_rf    <- confusionMatrix(pre_rf, test$diabetes)

cm_rf

```

```{r}

plot(learn_rf, main="Random Forest (Error Rate vs. Number of Trees)")

```



#### Prediction Plot


```{r}

plot(margin(learn_rf,test$diabetes))

```



##### Variance Importance Plot

```{r}

varImpPlot(learn_rf)

```




